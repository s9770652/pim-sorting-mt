\subsection*{Evaluation of the Performance}
\label{sec:tasklet:quick:performance}
\addcontentsline{toc}{subsection}{\nameref{sec:tasklet:quick:performance}}

\pgfplotsinvokeforeach{sorted,reverse,almost,uniform,zipf,normal}{
	\pgfplotstablereadnamed{data/quick/matrix/iterative/Median_of_random/right/uint32/#1.txt}{tableQuickRand_32#1}
	\pgfplotstablereadnamed{data/quick/matrix/recursive/Median_of_random/right/uint64/#1.txt}{tableQuickRand_64#1}
}

\begin{figure}
	\tikzsetnextfilename{quick_runtime}
	\begin{tikzpicture}[plot]
		\begin{groupplot}[
			adaptive group=1 by 2,
			groupplot ylabel={Cycles / \((n \lb n)\)},
			x from 16 to 1024,
			ytick distance=10,
		]
			\nextgroupplot[title/.add={}{32-bit}, ymin=30, ymax=80]
			\pgfplotsset{legend to name=leg:quick:runtime, legend entries={Sorted, Reverse S., Almost S., Uniform, Zipf's, Normal}}
			\pgfplotsinvokeforeach{sorted,reverse,almost,uniform,zipf,normal}{
				\plotpernlogn{TrivialBC}{tableQuickRand_32#1}
			}
			%
			\nextgroupplot[title/.add={}{64-bit}, ymin=40,ymax=90]
			\pgfplotsinvokeforeach{sorted,reverse,almost,uniform,zipf,normal}{
				\plotpernlogn{TrivialBC}{tableQuickRand_64#1}
			}
		\end{groupplot}
	\end{tikzpicture}

	\hfil\pgfplotslegendfromname{leg:quick:runtime}\hfil
	\caption{
		Average runtime of \QS{} on all tested input distributions and data types.
	}
	\label{fig:quick:runtime}
\end{figure}

\Cref{fig:quick:runtime} shows the runtime of \QS{} in it default configuration, that is, with random medians.
\Cref{fig:quick:runtime_uint32,fig:quick:runtime_uint64} additionally contain the runtimes with deterministic medians.
The average runtimes are rather close across all input distributions, a consequence of using random medians and of considering elements equal to the pivot as different.
In fact, it is \IS{} that primarily causes the discrepancies, as setting the threshold to 1 proves.
This also explains why \QS{} performs so well on large inputs with Zipf's distribution:
This distributions generates many duplicates, which are put into the same partitions, logically, so \IS{} scans many partitions once and is done.

One might expect \QS{} to perform even better on sorted and reverse sorted input, since everything is either already in the correct position or because the two pointers quickly invert large swaths of the inputs.
However, a side effect of placing the pivot first at the end of a partition and later somewhere in the middle can be that many elements are misplaced by one position from where they should be in the sorted input and some elements are placed very far from their end positions.
Take reverse sorted inputs and the deterministic median as an example:
The element \(n/2\) is chosen as pivot out of \(n\), \(n/2\), and \(0\) and then gets swapped with the last element, that is, with \(0\).
Thereupon, the pointers invert the rest of the input such that the start of the input looks something like \(1, 2, \dots, n/2-1, 0, n/2, \dots\) after the first partitioning step.
Indeed, this pattern makes \QS{} with deterministic medians degrade and eventually overflow the call stack, which is why the respective plots in \cref{fig:quick:runtime_uint32,fig:quick:runtime_uint64} leave the charts.

There are ways to implement \QS{} without such a switching of the pivot.
Then, however, the pivot does not act as implicit sentinel value anymore, and, furthermore, exploratory implementations did not yield a clear picture on whether the performance on more random distributions suffers.
