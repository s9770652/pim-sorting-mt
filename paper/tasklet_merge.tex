\section{\texorpdfstring{\MS{}}{MergeSort}}
\label{sec:tasklet:merge}

Two-way bottom-up \MS{}~\cites{katajainen1997meticulous}[85\psq]{maurer1974datenstrukturen}[Chapter~2.3.1]{wirth1975algorithmen} repeatedly compares two elements and \emph{merges} them to form sorted pairs.
Once only pairs (and perhaps one single element) remain, the pairs are merged into quadruplets, the quadruples into octuplets and so on until a single sorted sequence remains.
Sorted sequences are also referred to as \emph{runs}.
\MS{} has a guaranteed runtime of \(\bigoh{n \log n}\) and is the only stable sorting algorithm with subquadratic runtime presented in this \lcnamecref{sec:tasklet}.
Its biggest drawback is that additional space of size \(\bigtheta{n}\) is needed.


\paragraph{Starting Runs}
Instead of starting by merging runs of length 1, that is individual elements, it is beneficial to first subdivide the input and use either \IS{} or \ShS{} on the individual subdivisions.
These larger \emph{starting runs} allow to skip a few of the early rounds of merging.
For simplicity, all starting runs have the same, predefined length with possible exception of the last one which can be shorter.
A substantial downside to \ShS{} is that whilst it does allow to sort bigger starting runs quicker, it is not stable unlike \IS{}.
If \MS{} is supposed to sort stably, then \IS{} has to be used.

Unlike \QS{}, where each partition naturally acts as sentinel for the subsequent one, it is necessary to temporarily place sentinels values in front of each starting run and later restore the overwritten values of the preceding run.
The step sizes used for \ShS{} \Dash namely \(\stepsizes = (1, 6)\) for up to 48 elements, and \(\stepsizes = (1, 5, 12)\) for any more \Dash have been chosen based on the findings in \cref{sec:tasklet:shell}, according to which these step sizes offer top performance for uniformly distributed inputs and medial performance for reverse sorted inputs.
Spot-check inspection suggest no deterioration of \IS{}'s and \ShS{}'s compilation due to inlining.


\paragraph{Memory Footprint}
A simple implementation of \MS{} (denoted by \emph{full-space}) writes all merged runs to an auxiliary array, raising the need for space for \(n\) additional elements.
After a round is finished and all pairs of runs have been merged, the input array and the auxiliary array switch roles, and the merging begins anew.
Are the final sorted elements supposed to be saved in the original input array, a final round with a write-back from the auxiliary array to the input array is needed if the number of rounds is odd.

A slightly more sophisticated implementation (denoted by \emph{half-space}) needs space for only \(n/2\) additional elements:
When two adjacent runs are to be merged, the first one is copied to an auxiliary array.
Then, the copy and the second run are merged to the beginning of the first run.
As a side effect, no write-back is ever needed and, additionally, the merging of two runs can be terminated prematurely once the last element of the copied run is merged, since the last elements of the other run are already in place.
Strictly speaking, the auxiliary array holds~\(n-1\) elements in the worst-case.
By way of example, if the starting run length is \(n - 1\), there would be two runs of lengths \(n - 1\) and \(1\), respectively, and the first one would be copied away.
However, both the maximum number of elements to sort and the starting run length are predetermined, so the memory footprint can indeed be halved compared to the full-space \MS{}.

Further optimised, half-space \MS{} would not need to copy the first runs immediately.
It suffices to search for the foremost element of the first run which is greater than the first element of the second element.
All previous elements are already in the correct position so only the following elements need to be copied to the auxiliary array.
This \emph{deferred} copying, although examined during development, was not in use when measuring runtimes since it unfortunately complicates the following optimisation.


\paragraph{Unrolling}
There are four common reasons for \emph{flushing}, that is, writing \Dash many oftwhiles \Dash consecutive elements:
\begin{enumerate}
	\item
	When two runs are merged and the end of one of them is reached, the remaining elements of the other one can be moved safely to the output location.
	Especially with the sorted, reverse sorted, and almost sorted input distributions, the number of remaining elements will be high.

	\item
	The number of runs is odd, so the full-space \MS{} moves the last run to the output location unconditionally.

	\item
	The full-space \MS{} may write all elements from the auxiliary array back to the input array if the former contains the final sorted sequence.

	\item
	Before each merger of a pair of runs, the half-space \MS{} copies the first run to the auxiliary array.
\end{enumerate}
Therefore, flushing accounts for a considerable part of the runtime, and reducing the loop overhead (variable incrementation and bounds checking) is helpful.
This can be done via \emph{unrolling}:
As long as at least, let us say, \(x\) elements still need to be flushed, a loop with step size \(x\) is executed, and in each iteration, \(x\) elements are moved.
Is \(x\) a compile-time constant, the compiler implements the moving of the elements through \(x\) instruction which use constant, pre-calculated offsets.
Once less than \(x\) elements remain, an ordinary loop with step size \(1\), which moves elements individually, is used.
In good cases, this approach reduces the loop overhead to an \(x\)th, whilst in bad cases, where less than \(x\) elements are to be flushed, the overhead is increased by one additional check.

Due to time reasons, we refrained from doing automatic and extensive tests and relied on manual and exploratory tests to come up with the following strategy:
When the full-space \MS{} performs a write-back or when the half-space \MS{} copies the first run, \(x\) is set to the starting run length.
In all other cases, \(x\) is set to 24.
This strategy, albeit not optimal, makes the \MS*{} significantly faster:
Sorting sorted, reverse sorted, and almost sorted inputs gets faster by up to 30\%, while sorting more random inputs still get faster for the most part and slower by low single-digits at worst, depending on the starting run length.

\input{tasklet_merge_compilation}

\input{tasklet_merge_performance}
