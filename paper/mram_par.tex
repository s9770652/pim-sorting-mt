\section{Parallel \texorpdfstring{\MS{}}{MergeSort}}
\label{sec:par}

A simplistic way to parallelise \MS{} is the following:
Let us assume that the number of tasklets is a power of two and that they are numbered starting from 0.
The whole input array is divided into as many shares of equal length as there are tasklets, and each tasklet sorts a share sequentially using the \ac{MRAM} \MS{} of \cref{sec:mram:merge}.
Once finished, Tasklet \(t\) with \(t \bmod 2 = 1\) informs Tasklet \(t - 1\) that it is finished with sorting its share, and gets permanently suspended.
Tasklet \(t - 1\) merges its original share and the share of Tasklet \(t\) into a bigger run.
Once finished, Tasklet \(t\) with~\(t \bmod 4 = 2\) informs Tasklet \(t - 2\) that it is finished with sorting its share, and gets permanently suspended.
Then, Tasklet \(t - 2\) merges its original share with that of Tasklet \(t\).
This scheme is continued until only two runs remain which get merged by Tasklet~0.

The bottleneck is the sequential execution of each merge which eventually leads to an overall sequentially executed algorithm in the last round.
Even with infinite many processors, this simplistic parallel \MS{} can achieve a theoretical parallel speedup of at most \(\bigtheta{\log n}\).
\Citeauthor{cormen2013algorithmen}~\cite{cormen2013algorithmen} propose an alternative approach whose maximum theoretical parallel speedup is \(\bigtheta{n / \log^2 n}\).
One of its advantage is that the merge procedure does not change fundamentally.
Also, the number of synchronisation points is logarithmic in the number of tasklets only and the time which each synchronisation takes is insignificant compared to the total runtime.

\input{mram_par_aspects}

\input{mram_par_performance}
