\section{A \texorpdfstring{\MS{}}{MergeSort} for MRAM Data}
\label{sec:mram:merge}

The MRAM \MS{} is based on the half-space WRAM \MS{} as presented in \cref{sec:tasklet:merge} so only the adaptations of the merge process to the two-tier memory hierarchy are discussed.
A precondition for the presented algorithm to work is that the sizes of both runs are multiples of 8.
This precondition simplifies DMAs and is trivially met for 64-bit elements.
To meet it for 32-bit elements, the parallel \MS{} (\cref{sec:par}) divides the work amongst tasklets accordingly and, if need be, introduces dummy elements.
First, the general MRAM merge process with basic optimisations is presented.
Thereafter, we discuss several optimisations concerning sequential readers.


\subsection{Merging in the MRAM}

The underlying idea is the following:
First, initialise a sequential reader on either run.
Then, repeatedly compare the current elements, write the less element to the cache, and read the next element.
Whenever the cache is full, empty it by writing its content to the output location.
Once the end of the run with the less tail element is reached, stop comparing and empty the cache.
Since the sorting algorithm is based on half-space \MS{}, the merging is now done if the run with the less tail element was the first run, as the remainder of the second run is already in the correct position.
If the run with the less tail element was the second run, flush the first run by transferring its remainder from the MRAM to the output location with the help of the entire triple buffer.

During merging, checks on both the depletion\todo{Bezeichnung schon in \cref{sec:tasklet} einführen!} of the less run\todo{ebenso} and the fill level of the cache are needed.
For this reason, the merge process (\cref{alg:two-tier merge}) consists of two tiers, with the first one having a reduced number of depletion checks and with both making use of unrolled loops to reduce the number of fill level checks.
The first tier is in operation as long as there are at least \unrollfactor{} many elements left to merge in the less run.
This is verifiable through the function \lstinline|seqread_tell|, which returns the corresponding MRAM address of an element within a sequential-read buffer.
First, an unrolled loop with \unrollfactor{} many iterations is executed, with each iteration comparing the current elements of both runs, writing the less element to the cache, and advancing the respective pointer (\cref{alg:unrolled loop}).
Afterwards, it is checked whether the cache is filled with \unrolledcachelength{} many elements, with \unrolledcachelength{} being a multiple of \unrollfactor{} and \(\unrolledcachelength{} \times \text{\lstinline[keywords={}]|sizeof(T)|} \le \text{\lstinline|CACHE_SIZE|}\) being a multiple of 8.
If the fill level is too low, it is jumped back to the beginning of the tier and the number of remaining elements checked anew.
If, however, the maximum fill level is indeed reached, the cache is emptied before jumping back to the beginning of the tier.
Because of \(\unrolledcachelength{} \times \text{\lstinline[keywords={}]|sizeof(T)|}\) being a multiple of 8, emptying the cache is possible through a simple call of \lstinline|mram_write|.

Once the first tier comes to an end because the elements left in the less run are too few, it is checked whether the less run is depleted.
If so, the cache is emptied and the remainder of the greater run is flushed.
To do the latter, the data is iteratively transferred from its original position in the MRAM to the output location using \lstinline|mram_read| and \lstinline|mram_write|.
Since the sequential readers are of no use anymore, the whole triple buffer may be used during the transfer in case that the cache size is below \qty{2048}{\byte}.
Should the number of elements within the cache be odd and the input be 32-bit elements, the size of the cache content is not a multiple of 8.
Furthermore, the size of the remainder of the greater run is also not a multiple of 8 then, given that both the sizes of two runs as well as \unrolledcachelength{} × \lstinline[keywords={}]|sizeof(T)| were such.
For this reason, the current element of the greater run is moved to the cache to bring the size of its content to a multiple of 8, making calling \lstinline|mram_write| to empty the cache and flush the remainder unproblematic.

\NewDocumentCommand{\codeparttitle}{m}{\nonl\textsf{\textbf{\uppercase{#1}}}}
\SetArgSty{}
\SetFuncArgSty{}
\SetKw{KwAnd}{and}
\SetKw{KwContinue}{continue}
\SetKw{KwT}{T}

\SetKwArray{Cache}{cache}
\SetKwArray{Currs}{curr}
\SetKwArray{Ends}{ends}
\SetKwArray{Readers}{readers}

\SetKwData{Early}{early\_end}
\SetKwData{Factor}{\unrollfactor*}
\SetKwData{Length}{\unrolledcachelength*}
\SetKwData{Out}{out}

\SetKwFunction{Get}{seqread\_get}
\SetKwFunction{Read}{mram\_read}
\SetKwFunction{SizeOf}{sizeof}
\SetKwFunction{Tell}{seqread\_tell}
\SetKwFunction{Write}{mram\_write}

\begin{algorithm*}[!t]
	\KwData{%
		sequential readers \Readers{\(2\)},
		pointers \Currs{\(2\)} to current elements,
		pointers \Ends{\(2\)} to tail elements,
		output location \Out,
		cache \Cache
	}
	\KwResult{%
		both runs merged together and written to \Out
	}

	\(i\) ← \(0\)  \tct*{number of elements in cache}
	\Early ← \Ends{\(1\)} – \Factor + \(1\)\;
	\While(\tct*[f]{first tier}){\Tell{\Currs{\(1\)}, \Readers{\(1\)}} ≤ \Early}{
		Merge \Factor many elements \linebreak without checking for depletion (\cref{alg:unrolled loop}).\;
		\If{\(i\) ≤ \Length}{
			\KwContinue  \tct*{skips cache emptying}
		}
		\Write{\Cache, \Out, \Length × \SizeOf{\KwT}}\;
		\(i\) ← \(0\)\;
		\Out ← \Out + \Length\;
	}
	\If{\Tell{\Currs{\(1\)}, \Readers{\(1\)}} > \Ends{\(1\)}}{
		Empty the cache.\;
		Flush the first run.\;
		\Return\;
	}
	\While(\tct*[f]{second tier}){true}{
		Merge \Factor many elements \linebreak with checking for depletion (\cref{alg:unrolled loop}).\;
		\If{\(i\) ≤ \Length}{
			\KwContinue  \tct*{skips cache emptying}
		}
		\Write{\Cache, \Out, \Length × \SizeOf{\KwT}}\;
		\(i\) ← \(0\)\;
		\Out ← \Out + \Length\;
	}

	\caption{
		Two-tier merging of two MRAM runs, where the second one is the less run.
		In the event of the first run being less, flip all indices and omit flushing the other run.
	}
	\label{alg:two-tier merge}
\end{algorithm*}

If, however, the less run is not yet depleted, the second tier begins.
This one is structurally equal to the first tier with a single exception, for there is no guarantee that the unrolled loop will be executed in full:
The depletion check now happens whenever an element of the less run is written to the cache.
When it occurs, the cache is emptied and the greater run is flushed, completing the merging.

\begin{algorithm*}[!t]
	\KwData{%
		sequential readers \Readers{\(2\)},
		pointers \Currs{\(2\)} to current elements,
		pointers \Ends{\(2\)} to tail elements,
		output location \Out,
		cache \Cache,
		number \(i\) of elements in the cache
	}
	\KwResult{%
		\Factor many elements merged to \Cache{\(i\) .. \(i\) + \Factor – \(1\)}
	}

	\For(\tct*[f]{unrolled loop}){\(k\) ← \(1\) \KwTo \Factor}{
		\eIf{*\Currs{\(0\)} ≤ *\Currs{\(1\)}}{
			\Cache{\(i\)++} ← *\Currs{\(0\)}\;
			\Currs{\(0\)} ← \Get{\Currs{\(0\)}, \Readers{\(0\)}}\;
		}{
			\Cache{\(i\)++} ← *\Currs{\(1\)}\;
			\Currs{\(1\)} ← \Get{\Currs{\(1\)}, \Readers{\(1\)}}\;
			\If(\tct*[f]{omit in tier 1}){\Tell{\Currs{\(1\)}, \Readers{\(1\)}} = \Ends{\(1\)}}{
				Empty the cache.\;
				Flush the first run.\;
				\Return  \tct*{stops \cref{alg:two-tier merge}}
			}
		}
	}

	\caption{
		Merging \unrollfactor{} many elements.
		This algorithm is part of \cref{alg:two-tier merge}, meaning any change to a variable carries over.
		In the event of the first run being less, flip the indices in the inner if statement and move it up into the outer if block.
	}
	\label{alg:unrolled loop}
\end{algorithm*}

%\begin{algorithm*}
%	\KwData{%
%		sequential readers \Readers{\(2\)},
%		pointers \Currs{\(2\)} to current elements,
%		output location \Out,
%		cache \Cache,
%		number \(i\) of elements in the cache
%	}
%	\KwResult{%
%		all merged elements written to the output
%	}
%
%	\If(\tct*[f]{always false for 64-bit integers}){\SizeOf{\KwT} = \(4\) \KwAnd \(i\) \(\bmod\) \(2\) ≠ \(0\)}{
%		\Cache{\(i\)++} ← *\Currs{\(0\)}  \tct*{Now, the number of elements in the cache is even.}
%		\Currs{\(0\)} ← \Get{\Currs{\(0\)}, \Readers{\(0\)}}\;
%	}
%	\Write{\Cache, \Out, \(i\) × \SizeOf{\KwT}}  \tct*{The transfer size is always divisible by 8.}
%	\Out ← \Out + \(i\)\;
%
%	\caption{
%		Emptying the cache.
%		This algorithm is part of \cref{alg:two-tier merge,alg:unrolled merge}, meaning any change to a variable carries over.
%	}
%	\label{alg:flush cache}
%\end{algorithm*}
%
%\begin{algorithm*}
%	\SetKwData{From}{from}
%	\SetKwData{MaxTransferS}{MAX\_TRANSFER\_SIZE}
%	\SetKwData{MaxTransferL}{MAX\_TRANSFER\_LENGTH}
%	\SetKwData{Size}{size}
%	\SetKwData{TBS}{\triplebuffersize*}
%
%	\KwData{%
%		sequential readers \Readers{\(2\)},
%		pointers \Currs{\(2\)} to current elements,
%		pointers \Ends{\(2\)} to tail elements,
%		output location \Out,
%		cache \Cache
%	}
%	\KwResult{%
%		every non-merged element of the first run written behind the merged elements in the output
%	}
%
%	\MaxTransferS ← \(\min\{ \TBS, 2048 \}\)\;
%	\MaxTransferL ← \MaxTransferS \,/ \SizeOf{\KwT}\;
%	\Size ← \MaxTransferS  \tct*{size of current transfer}
%	\From ← \Tell{\Currs{\(0\)}, \Readers{\(0\)}}  \tct*{first byte to transfer}
%	\While{\From ≤ \Ends{\(0\)}}{
%		\If{\From + \MaxTransferL – \(1\) > \Ends{\(0\)}}{
%			\Size ← (\Ends{\(0\)} – \From + \(1\)) × \SizeOf{\KwT}  \tct*{smaller size on last transfer}
%		}
%		\Read{\From, \Cache, \Size}\;
%		\Write{\Cache, \Out, \Size}\;
%		\From ← \From + \MaxTransferL  \tct*{May be wrong on the last transfer …}
%		\Out ← \Out + \MaxTransferL  \tct*{… but pointers are useless then, anyway.}
%	}
%
%	\caption{
%		Flushing the remainder of the non-depleted Run 0.
%	}
%	\label{alg:flush run}
%\end{algorithm*}

%\begin{figure}[p]
%	\begin{subfigure}{\textwidth}
%		\begin{lstlisting}[language={[DPU]Assembler}, mathescape, keepspaces]
%	add rcurr, rcurr, 8, nc10, .LABEL  // curr ← curr + 8; jump if no carry bit 10
%	add rreader, r22, -120             // get address of reader in the WRAM
%	lw rmram, rreader, 4               // load MRAM address of reader
%	add rmram, rmram, 1024             // MRAM address ← MRAM address + 1024
%	sw rrdr, 4, rreader                // store new MRAM address in reader
%	lw rwram, rreader, 0               // load buffer address of reader
%	ldma rwram, rmram, 255             // load (255 + 1) $×$ 8 bytes from the MRAM
%	add rcurr, rcurr, -1024            // curr ← curr - 1024
%.LABEL:\end{lstlisting}
%		\caption{
%			The assembler code as generated by \lstinline|__builtin_dpu_seqread_get|.
%			In some cases, line 2 is omitted, namely when the address of the reader is kept in an own register.
%		}
%	\end{subfigure}
%
%	\begin{subfigure}{\textwidth}
%		\begin{lstlisting}[language={[DPU]Assembler}, mathescape, keepspaces]
%	add rcurr, rcurr, 8, nc11, .LABEL  // curr ← curr + 8; jump if no carry bit 11
%	add rmram, rmram, 2048             // MRAM address ← MRAM address + 2048
%	ldma rwram, rmram, 255             // load (255 + 1) $×$ 8 bytes from the MRAM
%	add rcurr, rcurr, -2048            // curr ← curr - 2048
%.LABEL:\end{lstlisting}
%		\caption{
%			The handwritten assembler code.
%		}
%	\end{subfigure}
%	\caption{
%		Comparison of the assembler codes of the regular function \lstinline|seqread_get|, which calls \lstinline|__builtin_dpu_seqread_get|, and the improved one, which is handwritten.
%		In both cases, elements are \qty{8}{\byte} large and \lstinline|SEQREAD_CACHE_SIZE| is set to 1024.
%	}
%\end{figure}
