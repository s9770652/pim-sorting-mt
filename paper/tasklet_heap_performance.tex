\subsection*{Evaluation of the Performance}
\label{sec:tasklet:heap:performance}
\addcontentsline{toc}{subsection}{\nameref{sec:tasklet:heap:performance}}

\pgfplotsinvokeforeach{sorted,reverse,almost,uniform,zipf,normal}{
	\pgfplotstablereadnamed{data/heap/uint32/#1.txt}{tableHeap_32#1}
	\pgfplotstablereadnamed{data/heap/uint64/#1.txt}{tableHeap_64#1}
}

\pgfplotsset{
	heap/.style={
		adaptive group=1 by 2,
		groupplot ylabel={Cycles / \((n \lb n)\)},
		x from 16 to 1024,
	},
}

\def\heapalgos{HeapOnlyDown,HeapUpDown,HeapSwapParity}

\begin{figure}
	\tikzsetnextfilename{heap_runtime}
	\begin{tikzpicture}[plot]
		\begin{groupplot}[heap, ytick distance=5]
			\nextgroupplot[title/.add={}{32-bit}, ymin=130, ymax=155, legend to name=leg:heap:runtime]
			\legend{\HS{} (top-down), \HS{} (bottom-up), \HS{} (swap parity)}
			\expandafter\pgfplotsinvokeforeach\expandafter{\heapalgos}{
				\plotpernlogn{#1}{tableHeap_32uniform}
			}
			%
			\nextgroupplot[title/.add={}{64-bit}, ymin=155, ymax=180]
			\expandafter\pgfplotsinvokeforeach\expandafter{\heapalgos}{
				\plotpernlogn{#1}{tableHeap_64uniform}
			}
		\end{groupplot}
	\end{tikzpicture}

	\hfil\pgfplotslegendfromname{leg:heap:runtime}\hfil
	\caption{
		Comparison of the runtimes of three different \HS{} implementations on uniformly distributed integers.
	}
	\label{fig:heap:runtime}
\end{figure}

The measurements are visualised in \cref{fig:heap:runtime,fig:heap:runtime_uint32,fig:heap:runtime_uint64}.
In general, the performance of \HS{} is hardly volatile and barely depends on the input distribution.
Reverse sorted inputs are sorted the fastest since they are already max-heaps so the heap-building phase is brief, whereas sorted inputs are sorted the slowest since they are min-heaps essentially needing inversion.
Nonetheless, the reverse sorted inputs get sorted at most 10\% faster the sorted ones.

The normalised runtimes of the top-down \HS{} and the bottom-up \HS{} with swap parity show a slight upwards trends, whereas that of the bottom-up \HS{} with swap disparity mostly shows a slight downwards trends.
The exception are reverse sorted inputs, where bottom-up \HS{} also shows an upwards trend, albeit even slighter.
Interesting are their rankings relative to each other:
Value checks on 64-bit integers take two instructions, so that the savings of the bottom-up \HS{} with swap disparity allow it to outperform the top-down \HS{} even for short inputs.
Its advantage grows with the input length which makes sense as roughly 50\% of the vertices are leaves and 25\% are fathers of leaves, no matter the total size.
Therefore, the percentage of former last leaves sifting down from the top to the bottom remains steady but the travelled distance increases.
Value checks on 32-bit integers, on the other hand, take only one instruction, so that the reduction of these is overshadowed by the increased overhead from the longer downwards-sifting and the added upwards-sifting, whence the lead of the top-down \HS{}.
Indeed, at around 2000 elements, the bottom-up \HS{} with swap disparity overtakes the top-down \HS{} because of their inverse trends, but the lead stays narrow even at 6000 elements.
However, these long inputs are uninteresting due to the limited WRAM and the multiple tasklets used in most applications.

The bottom-up \HS{} with swap parity consistently trails behind.
This comes as no surprise since the overhead of its considerably prolonged upwards-sifting bears no proportion to the few swaps saved.
This holds true even for 64-bit integers as moves still cost only one instruction.
Unrolling the upwards-sifting proved to be unhelpful.
