\section{\texorpdfstring{\QS{}}{QuickSort}}
\label{sec:tasklet:quick}

\QS{} \cite{hoare1962quicksort} uses partitioning to sort in an expected average runtime of \(\bigoh{n \log n}\) and a worst-case runtime of \(\bigoh{n^2}\):
A pivot element is chosen from the input array, then the input array gets scanned and elements greater or lesser than the pivot are moved to the right or left side of the array, respectively.
Finally, \QS{} is used on the left and right side (the \enquote{partitions}).
\QS{} does not sort in-place, as additional space of size \(\bigoh{\log n}\) is needed for a call stack.
Furthermore, \QS{} is not stable.


\paragraph{Sentinel Values}
The partitioning is implemented using \citeauthor{hoare1962quicksort}'s original scheme \cite{hoare1962quicksort}:
At the start of each partitioning step, a pivot \lstinline|p| is chosen and swapped with the last element.
Then, two pointers are set to either end of the partition.
The left pointer \lstinline|i| moves rightwards until finding an element at least as great as the pivot (\lstinline|*i >= p|), while the right pointer \lstinline|j| moves leftwards until finding an element at most as great as the pivot (\lstinline|*l <= p|).
The two elements found are in the wrong order so they are swapped, and the pointers move onwards.
This process continues until the pointers meet.
Finally, the pivot is swapped with the first element of the right partition.

Only an explicit check for whether the pointers have met after stopping is needed.
Since the elements of the partitions to the left are at most as great as the elements of the current partition, they naturally act as bounds check for the pointer moving rightwards.
The pivot at the end acts as bounds check for the pointer moving leftwards.
Since the leftmost partitions have no neighbour to the left, one explicit sentinel values set to the minimum possible value must be placed at the start of the input.
The downside to this approach is that elements equal to the pivot are also swapped.

\paragraph{Base Cases}

\begin{figure}
	\pgfplotstableset{
		create on use/n/.style={create col/copy column from table={data/quick/fallback/uint32/16.txt}{n}},
	}
	\pgfplotsinvokeforeach{14,15,16,17,18,19,20}{
		\pgfplotstableset{create on use/µ_#1_32/.style={create col/copy column from table={data/quick/fallback/uint32/#1.txt}{µ_TrivialBC}}}
		\pgfplotstableset{create on use/µ_#1_64/.style={create col/copy column from table={data/quick/fallback/uint64/#1.txt}{µ_TrivialBC}}}
	}
	\pgfplotstablenew[columns={n,µ_14_32,µ_15_32,µ_16_32,µ_17_32,µ_18_32,µ_19_32,µ_20_32,µ_14_64,µ_15_64,µ_16_64,µ_17_64,µ_18_64,µ_19_64,µ_20_64}]{\pgfplotstablegetrowsof{data/quick/fallback/uint32/16.txt}}{\tableQuickFallback}

	\tikzsetnextfilename{quick_fallback}
	\begin{tikzpicture}[plot]
		\begin{groupplot}[
			horizontal sep for labels,
			adaptive group=1 by 2,
			groupplot ylabel={Speed-up},
			x from 16 to 1024,
			ymin=0.993,
			ymax=1.001,
			extra y ticks={0.993,1.001},
			yticklabel style={/pgf/number format/.cd, precision=3, fixed, zerofill},
		]
			\nextgroupplot[title=32-bit\strut]
			\pgfplotsset{legend to name=leg:quick:fallback, legend entries={15,...,20}}
			\pgfplotsset{update limits=false} \addplot coordinates {(15,0.99)}; \pgfplotsset{update limits=true}
			\pgfplotsinvokeforeach{16,17,18,19,20}{
				\ifnumequal{#1}{18}{
					\addplot coordinates {(18,0.99)};
				}{
					\plotspeedup{#1_32}{18_32}{tableQuickFallback}
				}
			}
			%
			\nextgroupplot[title=64-bit\strut]
			\pgfplotsinvokeforeach{15,16,17,18,19}{
				\ifnumequal{#1}{17}{
					\addplot coordinates {(17,0.99)};
				}{
					\plotspeedup{#1_64}{17_64}{tableQuickFallback}
				}
			}
		\end{groupplot}
	\end{tikzpicture}

	\hfil\pgfplotslegendfromname{leg:quick:fallback}\hfil
	\caption{
		Speed-ups of \QS*{} with different thresholds (15--20) for when to fall back to \IS{} over a threshold of 18 elements (32-bit) and 17 elements (64-bit).
		Using \ShS{} was not beneficial overall, likely because many partitions fall below the thresholds.
	}
	\label{fig:quick:fallback}
\end{figure}

When only a few elements remain in a partition, \QS{}'s overhead predominates such that \IS{} lends itself as fallback algorithm.
As seen in \cref{fig:quick:fallback}, the optimal threshold for switching the sorting algorithm is 18 elements for 32-bit integers on uniform inputs and likely similar on inputs following Zipf's or normal distributions.
For 64-bit integers, the optimal threshold is 17 elements, but we set 18 elements to be the default threshold for both data types to simplify matters since the impact is minuscule.
Up to 40\% of the runtime is saved compared to a \QS{} never falling back.
For sorted and almost sorted inputs, the threshold is higher since \IS{} is very fast on them so falling back earlier and, thus, ending the sorting process is better.
The same is true for reverse sorted inputs even though these are the worst-case inputs for \IS{} because \QS{}'s two pointers invert large swaths of the input.
However, these input distributions should be catered for by a pattern-defeating \QS{} as laid out in \cref{sec:tasklet:conclusion}, hence the 18 elements as default threshold.

To avoid unnecessary uses of \IS{}, another base case is imaginable, namely terminating when a partition contains at most 1 elements.
There are tremendous consequences for the runtime depending on the exact implementation of the base cases, as shown later in \enquote{\nameref{sec:tasklet:quick:compilation}}.


\paragraph{Recursion vs.\ Iteration}
In theory, the question of whether a DPU algorithm should be implemented recursively or iteratively comes down to convenience.
Due to the uniform costs of instructions, jumping to the start of a loop or to the start of a function essentially costs the same, as does managing arguments automatically through the regular call stack and manually through a simulated one.
Furthermore, in case of \QS{}, the compiler turns tail-recursive calls into jumps back to the function start, so that one partition is sorted recursively and the other iteratively.
All this would suggest a recursive implementation due to the reduced maintenance.

In practice, it comes down to the compilation.
Even parts of the algorithms which are independent from the choice between recursion and iteration can be compiled differently, such that there are implementations where iteration is faster than recursion and the other way around.
Overall though, iterative implementations \emph{tend} to be compiled better with superior register usage and less instructions used for the actual \QS{} algorithm.


\paragraph{Partition Prioritisation}
Whether the left-hand or the right-hand partition is sorted first should not make any difference for the runtime but actually does so because of different compilation, as shown later in \enquote{\nameref{sec:tasklet:quick:compilation}}.
Always sorting the shorter partition first and putting the longer partition on the call stack guarantees that the problem size is at least halved each step, so that the call stack stores \(\bigoh{\log n}\) elements at most.
This approach, however, is linked to huge speed penalties, which is why it is advisable to always prioritise the same side;
in this Thesis, the right-hand partitions are prioritised.
An overflow of the call stack becomes unlikely with the right pivot choice.


\paragraph{Pivot Choice}
Another parameter to tune is the way in which the pivot is chosen.
The following were implemented and tested:
\begin{itemize}
	\item
	Using the \emph{last element} is the fastest way, requiring zero additional instructions.

	\item
	Taking the \emph{deterministic median} of three elements, namely the first, middle, and last one, is far more computationally expensive since the position of the middle element must be calculated, the median be determined, and the pivot be swapped with the last element of the array, where it acts as sentinel.

	\item
	A \emph{random element} is most efficiently drawn using an xorshift random number generator and rejection sampling \cite{lukas_geis}.

	\item
	The \emph{random median} is a combination of the previous two methods, where the median of three random elements is taken.
	For simplicity, there is no check on whether an element is drawn twice or thrice.
	Since the partitions are rather long, this should happen seldom, anyhow.
\end{itemize}
A median increases the chances of choosing a pivot that is neither particularly high nor particularly low.
This leads to more balanced partitions such that the call stack is less likely to overflow and the base cases are reached faster.
But even then it is still possible to construct inputs where the runtime climbs up to \(\bigtheta{n^2}\) \cite{erkiö1984worstcase}, as everything is moved to the same partition so that the problem size is reduced by only one element (namely the pivot) after each partitioning step.

The random pivots circumvent this problem.
Whilst the pivots could, by ill luck, also lead to the same unbalanced partitions as the deterministic pivots, the worst-case expected runtime is \(\bigoh{n \log n}\) \cite{blum2011probabilistic}.
Using the median of medians \cite{blum1973median} could guarantee a runtime of \(\bigoh{n \log n}\) but was not implemented because a performant implementation would probably be quite complex and its benefit minuscule for this Thesis.

The general trend, as seen in \enquote{\nameref{sec:tasklet:quick:compilation}}, is the following:
A median gets more beneficial for the average runtime, the longer the input becomes, and leads to small pay-offs in the end.
Moreover, the standard deviations of the runtimes are cut roughly in half, although not shown in the figures of \enquote{\nameref{sec:tasklet:quick:compilation}} for reasons of clarity.
If the input is known to be fairly random, a deterministic choice yields a noticeably speed-up.
However, the gain remains in the single digits percentage-wise, supporting the findings by \citeauthor{lukas_geis}~\cite{lukas_geis} that drawing random numbers is quite cheap.
For this reason, the median of three random elements is used as default configuration throughout this Thesis.


\input{tasklet_quick_compilation}
\input{tasklet_quick_performance}
