\section{The Sequential Reader}
\label{sec:mram:seq_reader}

It is technically possible to access data in the MRAM in the same way as data in the WRAM.
For example, \lstinline|var = arr[i]| is valid code no matter whether the array \lstinline|arr|, the variable \lstinline|var|, or the index \lstinline|i| have been declared to reside in the WRAM or the MRAM.
Such \emph{direct memory accesses} (DMAs) to the MRAM are translated into the assembler functions \lstinline|ldma| and \lstinline|sdma|, which load and store the respective data.
However, each DMA comes with an overhead, and accessing MRAM data in the same way as WRAM data means an execution of \lstinline|ldma| or \lstinline|sdma| on each access.
For this reason, the preferred way to load contiguous data from the MRAM is through the function \lstinline|mram_read|.
This function takes the MRAM address of the first byte to load, the WRAM address of a buffer where the data are to be stored, and the number of consecutive bytes to load.
Likewise, there is the function \lstinline|mram_write| for writing contiguous WRAM data to the MRAM.
Internally, these two \langC{} functions also make use of the assembler functions \lstinline|ldma| and \lstinline|sdma| but pass them the number of bytes to load, so that the overhead occurs only once and is spread amongst many bytes.
The effect is so high that, according to \citeauthor{mutlu2022Benchmarking}~\cite[11]{mutlu2022Benchmarking}, using \lstinline|mram_read| and \lstinline|mram_write| remains beneficial even if only an eighth of the transferred data is actually of interest.

However, the functions \lstinline|mram_read| and \lstinline|mram_write| do come with some constraints.
Both the target and the source address must be aligned on 8 bytes.
Also, the number of transferred bytes must be at least 8, at most 2048, and a multiple of 8.
Failing to fulfil these constraints can result in missing or corrupt data.
Furthermore, programmers are tasked with maintaining the WRAM buffer and transferring data at appropriate times, which, given that the WRAM is more than a thousand times smaller than the MRAM, is likely frequent.

Since processing MRAM data consecutively is a common occurrence, UPMEM provides a data structure called \emph{sequential reader}.
Through a set of \langC{} functions, these sequential readers automate the read-in process and, thereby, remove any need to care for the alignment of addresses or the loading of new data.
On top of that, UPMEM claims that \textquote{[\dots] this abstraction implementation has been optimized and will provide better performance than a standard \langC{} check of the cache boundaries.}~\cite[Memory management -- Sequential readers]{upmemSDK}

The size of the sequential-read buffer within the WRAM is determined by the compile-time constant \lstinline|SEQREAD_CACHE_SIZE|, which can be set to either 32, 64, 128, 256, 512, or 1024.
Initialising the buffer must be done once through the function \lstinline|seqread_alloc|, which is worth a closer look.
Remember that the heap is actually implemented as a never-decreasing stack.
This means that new memory is only ever allocated behind the \emph{stack pointer}, which stores the end of the stack.
For \(\text{\lstinline|SEQREAD_CACHE_SIZE|} = 2^i\), the \(i\) least significant bits of the first byte in the buffer are required to be zero, for reasons explained shortly.
Therefore, the stack pointer skips to the next multiple of \lstinline|SEQREAD_CACHE_SIZE| if not already on such a multiple.
Due to the nature of a stack, this has the drawback that the skipped WRAM memory can never be allocated for something else.
Finally, 2 × \lstinline|SEQREAD_CACHE_SIZE| many bytes are allocated, also for reasons explained shortly.
All in all, the memory footprint of a sequential-read buffer is at least 2 × \lstinline|SEQREAD_CACHE_SIZE| but fewer than 3 × \lstinline|SEQREAD_CACHE_SIZE| many bytes.

The function \lstinline|seqread_init| instructs a sequential reader and its buffer to load data from a specified MRAM address.
It also returns a pointer to the corresponding WRAM address of said MRAM address, which we will refer to as pointer to the \emph{current element}.
Conceptually, the whole MRAM is divided into \emph{pages} of size \lstinline|SEQREAD_CACHE_SIZE|.
To load data from a specific MRAM address, the given address is rounded down the the next multiple of \lstinline|SEQREAD_CACHE_SIZE|, which yields the beginning of the page containing the MRAM address.
Then, 2 × \lstinline|SEQREAD_CACHE_SIZE| many bytes are loaded so that the buffer holds two pages.
This way, data of some long, compound type at the end of the first page is fully loaded even if extending into the other page.

To access the current element, one simply dereferences the pointer returned by \lstinline|seqread_init|.
Calling the function \lstinline|seqread_get| advances this pointer by a given number of bytes, which cannot be greater than \lstinline|SEQREAD_CACHE_SIZE|;
this way of specifying bytes allows the sequential reader to support arbitrary data types.
Once the pointer to the current item ends up in the second half of the buffer, it is set \lstinline|SEQREAD_CACHE_SIZE| many bytes back so that it points to an address in the first half again.
Also, the MRAM address stored within the sequential reader is increased by \lstinline|SEQREAD_CACHE_SIZE| many bytes, and the next two subsequent pages are loaded.
This means that the page which was stored in the second half of the buffer so far is loaded again from the MRAM but stored in the first half this time.

The acclaimed speedup through more performant bounds checks happens within the function \lstinline|seqread_get|, which in turn calls the function \lstinline|__builtin_dpu_seqread_get|.
Inspecting the compilation of \lstinline|__builtin_dpu_seqread_get| reveals the use of \emph{carry bits}.
The instruciton \lstinline|add| which is used to increase the pointer by the specified number of bytes is capable of checking whether bit \(i\) generated a carry bit.
To be more precise, carry bit \(i\) is set to \(\text{\lstinline|op1[i : 0]|} + \text{\lstinline|op2[i : 0]|}\), where \lstinline|op1[i : 0]| and \lstinline|op2[i : 0]| are \(i + 1\) least significant bits of the two summands~\cite[DPU Handbook -- Specific Conditions Common To Addition and Subtraction]{upmemSDK}.
Due to the alignment of the buffer on a power of two and due to page sizes being also a power of two, the generation of such a carry bit signifies that the pointer to the current item left the first buffer half.
Next to detecting the generation of carry bit \(i\), the instruction \lstinline|add| is also capable performing a conditional jump dependant on whether the carry bit was generated or not.
This means that it takes just one instruction to advance the pointer, check the cache boundaries and skip \Dash if needed \Dash the subsequent instruction responsible for loading the next pages and resetting the pointer.
