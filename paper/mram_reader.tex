\section{The Sequential Reader}
\label{sec:mram:seq_reader}

A \ac{DMA} takes half a cycle per transferred byte.
On top of that, each reading \ac{DMA} comes with an additional overhead of  \qty{77}{\cycles} and each writing \ac{DMA} with an overhead of \qty{61}{\cycles}.
To dilute this overhead, \ac{MRAM} data is preferably processed in blocks using the functions \lstinline|mram_read| and \lstinline|mram_write|.
The benefit of blockwise processing is so high that, according to \citeauthor{mutlu2022Benchmarking}~\cite[11]{mutlu2022Benchmarking}, using \lstinline|mram_read| and \lstinline|mram_write| remains beneficial compared to accessing single \ac{MRAM} elements even if only an eighth of the transferred data are actually of interest.
However, the functions \lstinline|mram_read| and \lstinline|mram_write| do come with some constraints.
Both the target and the source address must be aligned to 8 bytes.
Also, the number of transferred bytes must be at least 8, at most 2048, and a multiple of 8.
Furthermore, programmers are tasked with maintaining a buffer in the \ac{WRAM} and transferring data at appropriate times, which, given that the \ac{WRAM} is more than a thousand times smaller than the \ac{MRAM}, is likely frequent.

Since processing \ac{MRAM} data consecutively is a common occurrence, \upmem{} provides a data structure called \emph{sequential reader}.
Through a set of \langC{} functions, a sequential reader automates the read-in process and, thereby, removes any need to care for the alignment of addresses or the loading of new data.
On top of that, \upmem{} claims that \textquote{\bibellipsis{} this abstraction implementation has been optimized and will provide better performance than a standard \langC{} check of the cache boundaries.}~\cite[Memory management -- Sequential readers]{upmemSDK}

Of course, a sequential reader still requires a \ac{WRAM} buffer.
Its size in bytes is determined by the compile-time constant \seqreadcachesize{}, which can be set to either 32, 64, 128, 256, 512, or 1024.
The allocation of the buffer on the heap happens through the function \lstinline|seqread_alloc| and is worth a closer look.
Remember that the heap is actually implemented as a never-decreasing stack.
This means that new memory is only ever allocated behind the heap pointer, which stores the end of the heap.
With \(\seqreadcachesize{} = \twotoi\), the \(i\) least significant bits of the first byte address in the buffer are required to be zero, for reasons explained shortly.
Therefore, the heap pointer skips to the next higher multiple of \seqreadcachesize{} if not already on such a multiple.
Due to the nature of a stack, this has the drawback that the skipped \ac{WRAM} memory can never be allocated for something else.
After the skip of the heap pointer, a total of \(2 × \seqreadcachesize{}\) many bytes are allocated, also for reasons explained shortly.
All in all, the memory footprint of a sequential-read buffer is at least \(2 × \seqreadcachesize{}\) many bytes and less than \(3 × \seqreadcachesize{}\) many.

The function \lstinline|seqread_init| instructs a sequential reader to load data from a specified \ac{MRAM} address into its buffer.
Conceptually, the whole \ac{MRAM} is divided into \emph{pages} of size \seqreadcachesize{}.
To load data from the specified \ac{MRAM} address, the address is rounded down the the next multiple of \seqreadcachesize{}, which yields the beginning of the page containing the \ac{MRAM} address.
Then, 2 × \seqreadcachesize{} many bytes are loaded so that the buffer holds two pages.
This way, data of some long, compound type at the end of the first page are fully loaded even if extending into the other page.

The function \lstinline|seqread_init| also returns a pointer to the corresponding position of the specified \ac{MRAM} address within the sequential-read buffer, to which we will refer as pointer to the \emph{current element}.
Due to the page model, this pointer may not be set to the beginning of the buffer.
To access the current element, one simply dereferences the pointer.
Calling the function \lstinline|seqread_get| advances this pointer by a given number of bytes, which cannot be greater than \seqreadcachesize{};
this way of specifying bytes allows the sequential reader to support arbitrary data types.
Once the pointer to the current element ends up in the second half of the buffer, it is set \seqreadcachesize{} many bytes back so that it points to an address in the first half again.
In addition, the \ac{MRAM} address from which to read is increased by \seqreadcachesize{} many bytes, and the next two subsequent pages are loaded.
This means that the page stored in the second half of the buffer is loaded from the \ac{MRAM} again but stored in the first half this time.
\Cref{fig:merge:reader} visualises an intermediate state of a sequential reader, showcasing its characteristic read behaviour.

\begin{figure}
	\centering
	\tikzsetnextfilename{sequential_reader}
	\begin{tikzpicture}[sketch, curr/.style={accentcolor}]
		% MRAM.
		\def\mramlen{20}
		\def\mramstart{-2}
		\def\mramend{6}

		\fill[excess] (\mramstart, 0) rectangle (                0, 1);
		\fill[excess] (  \mramlen, 0) rectangle (\mramlen+\mramend, 1);
		\draw[excess] (\mramstart, 0)      grid (                0, 1);
		\draw[excess] (  \mramlen, 0)      grid (\mramlen+\mramend, 1);

		\draw (0, 0) grid (\mramlen,1);

		% Buffer.
		\def\buflen{8}
		\def\bufxoffset{10}
		\def\buffyoffset{-3}

		\fill[excess] (0.5*\buflen+\bufxoffset+\mramstart, \buffyoffset) rectangle (\buflen+\bufxoffset+\mramstart, 1+\buffyoffset);
		\draw[excess] (0.5*\buflen+\bufxoffset+\mramstart, \buffyoffset)      grid (\buflen+\bufxoffset+\mramstart, 1+\buffyoffset);

		\draw(\bufxoffset+\mramstart, \buffyoffset) grid (0.5*\buflen+\bufxoffset+\mramstart, 1+\buffyoffset);

		% Mapping lines.
		\draw[               name path=M2Bl] (1.5*\buflen+\mramstart, 0) to[out=-90, in=90] (            \bufxoffset+\mramstart, 1+\buffyoffset);
		\draw[line cap=butt, name path=M2Br] (2.5*\buflen+\mramstart, 0) to[out=-90, in=90] (    \buflen+\bufxoffset+\mramstart, 1+\buffyoffset);
		\draw[                       dashed] (2.0*\buflen+\mramstart, 0) to[out=-90, in=90] (0.5*\buflen+\bufxoffset+\mramstart, 1+\buffyoffset);
		\tikzfillbetween[of=M2Bl and M2Br, split=false] {gray, ultra nearly transparent}

		% Current item.
		\def\currindex{2}

		\fill[curr, fill opacity=.1]   (\currindex+\bufxoffset+\mramstart,      \buffyoffset) rectangle (1+\currindex+\bufxoffset+\mramstart, 1+\buffyoffset);
		\draw[curr, ultra thick, fill] (\currindex+\bufxoffset+\mramstart,      \buffyoffset)      grid (1+\currindex+\bufxoffset+\mramstart, 1+\buffyoffset);
		\draw[curr, flow, ->]          (\currindex+\bufxoffset+\mramstart, 1.25+\buffyoffset)       --+ (0:1);

		% Item identifiers.
		\def\mramfirst{10}

		\pgfmathsetmacro{\looplastindex}{int(\mramlen+\mramend-1)}
		\foreach \i in {\mramstart,...,\looplastindex}{
			\pgfmathsetmacro{\itemindex}{int( 4*(\mramfirst+\i) )}
			\node[address] at (\i+0.5, 0.5) { \hexa{\itemindex} };
		}

		\pgfmathsetmacro{\looplastindex}{int(\buflen-1)}
		\foreach \i in {0,...,\looplastindex}{
			\pgfmathsetmacro{\itemindex}{int( 4*(\mramfirst+1.5*\buflen+\mramstart+\i) )}
			\node[address] at (\i+\bufxoffset+\mramstart+0.5, \buffyoffset+0.5) { \hexa{\itemindex} };
		}

		% Pointers.
		\def\ptrdist{0.65}

		\draw[ptr, <-] (1.5*\buflen+\mramstart+0.5, 1) -- +(90:\ptrdist) node[above] {\lstinline|from|};

		\draw[ptr, <-] (\bufxoffset+\mramstart+0.5, \buffyoffset) -- +(-90:\ptrdist) node[below] {\lstinline|buffer|};

		\draw[ptr, <-] (\currindex+\bufxoffset+\mramstart+0.5, \buffyoffset) -- +(-90:\ptrdist) node[below] {\lstinline|curr|\vphantom{\lstinline|f|}};
	\end{tikzpicture}

	\caption{
		An exemplary sequential reader with \seqreadcachesize{} set to 16 being used to transfer 32-bit elements from the \ac{MRAM} (top row) into the sequential-read buffer (bottom row).
		The hexadecimal numbers denote the addresses of the respective elements within the \ac{MRAM}.
		Only the elements with addresses from \lstinline|0x28| to \lstinline|0x74| are sought to be read, however, the page model requires that the elements with addresses \lstinline|0x20|, \lstinline|0x24|, and \lstinline|0x78| to \lstinline|0x8c| are also loaded at some point.
		The pointer \lstinline|buffer| constantly points to the beginning of the sequential-read buffer.
		The pointer \lstinline|from| points to the \ac{MRAM} address of the first byte within the buffer.
		The pointer \lstinline|curr| moves from left to right, 4 bytes at a time.
		No byte of the second half of the buffer is ever read as the elements fit perfectly within the first half.
	}
	\label{fig:merge:reader}
\end{figure}

The acclaimed speedup through more performant bounds checks happens within the function \lstinline|seqread_get|, which in turn calls the function \lstinline|__builtin_dpu_seqread_get|.
An inspection of its compilation with \(\seqreadcachesize{} = \twotoi\) reveals the use of a combo operation.
The pointer to the current element is advanced by invoking an \lstinline|add| instruction to increase the stored address.
This \lstinline|add| instruction uses a condition to detect the generation of the \(i\)th carry bit.
To be more precise, this carry bit is set to \(\text{\lstinline|op1[i:0]|} + \text{\lstinline|op2[i:0]|}\), where \lstinline|op1[i:0]| and \lstinline|op2[i:0]| are the \(i + 1\) least significant bits of the involved operands, in this case the pointer and the number of bytes to advance.~\cite[DPU Handbook -- Specific Conditions Common To Addition and Subtraction]{upmemSDK}
Thanks to the carefully chosen size and alignment of the buffer, the generation of such a carry bit signifies that the pointer to the current element has left the first buffer half.
This means that it takes just one instruction to advance the pointer, check the buffer boundaries and skip \Dash if needed \Dash the subsequent instruction responsible for updating the whole reader.
