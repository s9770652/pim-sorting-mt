\subsection{Investigation of the Compilation}
\label{sec:tasklet:merge:compilation}

\begin{figure}[p]
	\lstset{basicstyle=\ttfamily\small}
	\def\codewidth{0.34\linewidth}
	\newlength\assemblerwidth \setlength\assemblerwidth{0.595\linewidth}
	\begin{subfigure}{\textwidth}
		\begin{minipage}{\codewidth}
			\begin{lstlisting}[belowskip=3\baselineskip+\medskipamount]
#pragma unroll
for (int k = 0; k < 16; k++) {
	if (*i <= *j) {
		out[k] = *i++;
	} else {
		out[k] = *j++;
	}
}
			\end{lstlisting}
		\end{minipage}
		\hfill
		\begin{minipage}{\assemblerwidth}
			\begin{minipage}{ \widthof{\lstinline|	move rj, rtmp, true, .LABEL_k_out|} }
				\begin{lstlisting}[language={[DPU]Assembler}, mathescape, keepspaces]
$\textnormal{\textit{// iteration \texttt{k}}}$
	lw ri${}_{*}$, ri, 0
	lw rj${}_{*}$, rj, 0
	add rtmp, rj, 4
	jle ri${}_{*}$, rj${}_{*}$, .LABEL_k_i
	move ri${}_{*}$, rj${}_{*}$
	move rj, rtmp, true, .LABEL_k_out
.LABEL_k_i:
	add ri, ri, 4
.LABEL_k_out:
	sw rout, 4${}×{}$k, ri${}_{*}$
\end{lstlisting}
			\end{minipage}
			\hfill
			\begin{minipage}{ \widthof{\itshape// jump if \lstinline|*i| ≤ \lstinline|*j|} }
				\itshape\small
				\phantom{lg}

				// load \lstinline|*(i + 0)|

				// load \lstinline|*(j + 0)|

				// \lstinline|tmp| ← \lstinline|j| + \lstinline|1|

				// jump if \lstinline|*i| ≤ \lstinline|*j|

				// overwrite \lstinline[mathescape]|ri${}_{*}$|

				// \lstinline|j| ← \lstinline|tmp|; jump

				\phantom{lg}

				// \lstinline|i| ← \lstinline|i| + \lstinline|1|

				\phantom{lg}

				// \lstinline|out[k]| ← \lstinline|*i|
			\end{minipage}
		\end{minipage}
		\caption[]{
			This code takes 8 instructions per iteration.
			First, the pointers are dereferenced (lns.~2, 3).
			Then, the resulting address from incrementing pointer \lstinline|j| is calculated (ln.~4).
			If the first run contains the less current element, it is jumped to line~9, where pointer \lstinline|i| is incremented.
			Lastly, the less element \lstinline|*i| is written to the output (ln.~11).
			If the second run contains the less current element, the register holding \lstinline|*i| is overwritten with~\lstinline|*j| (ln.~7).
			Then, a combo operation (ln.~7) finally applies the result from incrementing pointer \lstinline|j| and jumps to the line where the output is set.

			\hspace*{1em}
			We do not know why pointer \lstinline|j| gets temporarily incremented.
			According to the documentation, an \lstinline|add| instruction is compatible with the \lstinline|true| flag, meaning the \lstinline|add| instruction in line~4 and the \lstinline|move| instruction in line~7 could be fused.
		}
		\label{fig:merge:load:twice}
	\end{subfigure}

	\begin{subfigure}{\textwidth}
		\begin{minipage}{\codewidth}
			\begin{lstlisting}[belowskip=2\baselineskip+\medskipamount+\smallskipamount]
int val_i = *i, val_j = *j;
#pragma unroll
for (int k = 0; k < 16; k++) {
	if (val_i <= val_j) {
		out[k] = val_i;
		val_i = *++i;
	} else {
		out[k] = val_j;
		val_j = *++j;
	}
}
			\end{lstlisting}
		\end{minipage}
		\hfill
		\begin{minipage}{\assemblerwidth}
			\begin{minipage}{ \widthof{\lstinline|	jgt ri*, rj*, .LABEL_k_j|~} }
				\begin{lstlisting}[language={[DPU]Assembler}, mathescape, keepspaces]
$\textnormal{\textit{// iteration \texttt{k} (\texttt{val\_i} ≤ \texttt{val\_j})}}$
	jgt ri${}_{*}$, rj${}_{*}$, .LABEL_k_j
.LABEL_k_i:
	sw rout, 4${}×{}$k, ri${}_{*}$
	add ri, ri, 4
	lw ri${}_{*}$, ri, 0
\end{lstlisting}
			\end{minipage}
			\hfill
			\begin{minipage}{ \widthof{\itshape// jump if \lstinline|val_i| > \lstinline|val_j|} }
				\itshape\small
				\phantom{lg}

				// jump if \lstinline|val_i| > \lstinline|val_j|

				\phantom{lg}

				// \lstinline|out[k]| ← \lstinline|val_i|

				// \lstinline|i| ← \lstinline|i| + \lstinline|1|

				// \lstinline|val_i| ← \lstinline|*(i + 0)|
			\end{minipage}
			\smallskip
			\begin{minipage}{ \widthof{\lstinline|	jgt ri*, rj*, .LABEL_k_j|~} }
				\begin{lstlisting}[language={[DPU]Assembler}, mathescape, keepspaces]
$\textnormal{\textit{// iteration \texttt{k} (\texttt{val\_i} > \texttt{val\_j})}}$
	jle ri${}_{*}$, rj${}_{*}$, .LABEL_k_i
.LABEL_k_j:
	sw rout, 4${}×{}$k, rj${}_{*}$
	add rj, rj, 4
	lw rj${}_{*}$, rj, 0
\end{lstlisting}
			\end{minipage}
			\hfill
			\begin{minipage}{ \widthof{\itshape// jump if \lstinline|val_i| > \lstinline|val_j|} }
				\itshape\small
				\phantom{lg}

				// jump if \lstinline|val_i| ≤ \lstinline|val_j|

				\phantom{lg}

				// \lstinline|out[k]| ← \lstinline|val_j|

				// \lstinline|j| ← \lstinline|j| + \lstinline|1|

				// \lstinline|val_j| ← \lstinline|*(j + 0)|
			\end{minipage}
		\end{minipage}
		\caption{
			This code takes 4 instructions per iteration.
			There are 16 cascaded iterations in the assembler code, all of them writing the elements of the first run to the output (top).
			There is an analogue cascade writing only elements of the second run to the output (bottom).
			Labels allow to switch between the cascades.
			First, it is checked whether the cascade should be changed (ln.~2).
			Then, the output is set (ln.~4), the respective pointer incremented (ln.~5), and the new value from dereferencing loaded (ln.~6).
		}
		\label{fig:merge:load:once}
	\end{subfigure}
	\caption{
		Two \langC{} implementations of an unrolled loop which merges 16 elements, contrasted with their compilations.
		Only the assembler codes of one iteration are shown, as all iterations follow the same scheme;
		a sixteenfold cascade of the given assembler codes yields the whole assembler codes of the loops.
		The pointers \lstinline|i| and \lstinline|j| point initially to the first elements of the runs.
		The serially numbered registers (\enquote{\lstinline|r|\dots}) and jump labels (\enquote{\lstinline|.LABEL|\dots}) were renamed to aid understanding.
		Note that the data type \lstinline[keywords={}]|int| is \qty{4}{\byte} large, which is why all offsets are multiples of four.
	}
	\label{fig:merge:load}
\end{figure}

\noindent
A significant portion of the runtime is spent on the repeated comparison of elements in a pair of runs, followed by a write of the less element to the output.
\Cref{fig:merge:load:twice} shows a straightforward implementation of an unrolled loop performing such comparisons and writes.
The code makes use of two pointers \lstinline|i| and \lstinline|j| which are initially set to the first elements of the runs.
To get their values, they are simply dereferenced.
After the output \lstinline|out[k]| has been set in iteration \lstinline|k|, the respective pointer of the less element is incremented.

Despite the succinctness of the \langC{} code, the resulting assembler code is of subpar quality.
Depending on the run from which an element got merged in the previous iteration, an iteration takes either 7 or 8 instructions.
This is a consequence of loading the values of both dereferenced pointers at the beginning of each iteration despite one of the values not having changed since the last iteration.
\Cref{fig:merge:load:once} shows an alternative implementation, whose compilation results in four instructions per iteration.
This was achieved by dereferencing the pointers \lstinline|i| and \lstinline|j| before the loop begins and storing the values in dedicated variables.
The comparisons and writes use only these dedicated variables, of which only one gets updated per iteration.
A more detailed description of the compilations is given in the caption of \cref{fig:merge:load}.

It can only be speculated as to the reason for the poor compilation of the simpler implementation.
Perhaps the constant reloads are related to the ability of tasklets to write to any \ac{WRAM} address.
Theoretically, it could be that the value obtained by dereferencing the non-incremented pointer changes between two subsequent iterations.
This explanation is not fully satisfactory as it would imply yet another load instruction before writing \lstinline|out[k]|.

Unluckily, only with the full-space \MS{} does this change to dedicated variables make iterations take 4 instructions unanimously.
With the half-space \MS{}, some merge iterations take 5 instructions.
The reason is that the second pointer \lstinline|j| is never incremented directly.
Instead, whenever an element of the second run is merged, a counter is incremented and, then, the new address of pointer \lstinline|j| is calculated by taking the address of the first element of the second run and adding the counter.
The fix is to change the loop which iterates over the pairs of runs to merge.
Rather than using the ends of the second runs as natural loop index, it has to be iterated over the ends of the first runs.

A last mention shall be given to the merge function used by the half-space \MS{}.
Passing the copied run as second argument and the uncopied run as the first one nets a noticeably speedup over an implementation with flipped arguments and, of course, flipped logic.
Sadly, we could not pinpoint the fundamental cause for this phenomenon.
